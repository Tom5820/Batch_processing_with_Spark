{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('C:\\Spark\\spark-3.1.3-bin-hadoop3.2')\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import types\n",
    "import pandas as pd\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green = spark.read.parquet('file\\green_tripdata_2021-01.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[7] at javaToPython at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_green.rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_green = df_green \\\n",
    "    .select('lpep_pickup_datetime', 'PULocationID', 'total_amount','') \\\n",
    "    .rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "start = datetime(year=2021, month=1, day=1)\n",
    "def filter_outliers(row):\n",
    "    return row.lpep_pickup_datetime >= start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(lpep_pickup_datetime=datetime.datetime(2021, 1, 1, 7, 15, 56), PULocationID=43, total_amount=6.8),\n",
       " Row(lpep_pickup_datetime=datetime.datetime(2021, 1, 1, 7, 25, 59), PULocationID=166, total_amount=16.86),\n",
       " Row(lpep_pickup_datetime=datetime.datetime(2021, 1, 1, 7, 45, 57), PULocationID=41, total_amount=8.3),\n",
       " Row(lpep_pickup_datetime=datetime.datetime(2021, 1, 1, 6, 57, 51), PULocationID=168, total_amount=9.3),\n",
       " Row(lpep_pickup_datetime=datetime.datetime(2021, 1, 1, 7, 16, 36), PULocationID=265, total_amount=-52.8)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_green.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(lpep_pickup_datetime=datetime.datetime(2021, 1, 1, 7, 15, 56), PULocationID=43, total_amount=6.8)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_green.filter(lambda row: row.lpep_pickup_datetime >= start ).take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_grouping(row): \n",
    "    hour = row.lpep_pickup_datetime.replace(minute=0, second=0, microsecond=0)\n",
    "    zone = row.PULocationID\n",
    "    key = (hour, zone)\n",
    "    \n",
    "    amount = row.total_amount\n",
    "    count = 1\n",
    "    value = (amount, count)\n",
    "\n",
    "    return (key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((datetime.datetime(2021, 1, 1, 7, 0), 43), (6.8, 1)),\n",
       " ((datetime.datetime(2021, 1, 1, 7, 0), 166), (16.86, 1)),\n",
       " ((datetime.datetime(2021, 1, 1, 7, 0), 41), (8.3, 1)),\n",
       " ((datetime.datetime(2021, 1, 1, 6, 0), 168), (9.3, 1)),\n",
       " ((datetime.datetime(2021, 1, 1, 7, 0), 265), (-52.8, 1)),\n",
       " ((datetime.datetime(2021, 1, 1, 7, 0), 265), (52.8, 1)),\n",
       " ((datetime.datetime(2021, 1, 1, 7, 0), 265), (216.36, 1)),\n",
       " ((datetime.datetime(2021, 1, 1, 7, 0), 75), (5.76, 1)),\n",
       " ((datetime.datetime(2021, 1, 1, 7, 0), 225), (3.8, 1)),\n",
       " ((datetime.datetime(2021, 1, 1, 7, 0), 225), (42.05, 1))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_green \\\n",
    "    .filter(filter_outliers) \\\n",
    "    .map(prepare_for_grouping) \\\n",
    "    .take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_revenue(left_value, right_value):\n",
    "    left_amount, left_count = left_value\n",
    "    right_amount, right_count = right_value\n",
    "    \n",
    "    output_amount = left_amount + right_amount\n",
    "    output_count = left_count + right_count\n",
    "    \n",
    "    return (output_amount, output_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((datetime.datetime(2021, 1, 1, 7, 0), 43), (6.8, 1)),\n",
       " ((datetime.datetime(2021, 1, 1, 7, 0), 166), (22.66, 2)),\n",
       " ((datetime.datetime(2021, 1, 1, 7, 0), 41), (8.3, 1)),\n",
       " ((datetime.datetime(2021, 1, 1, 6, 0), 168), (9.3, 1)),\n",
       " ((datetime.datetime(2021, 1, 1, 7, 0), 265), (216.36, 3)),\n",
       " ((datetime.datetime(2021, 1, 1, 7, 0), 75), (34.36, 3)),\n",
       " ((datetime.datetime(2021, 1, 1, 7, 0), 225), (85.41, 4)),\n",
       " ((datetime.datetime(2021, 1, 1, 7, 0), 244), (19.3, 1)),\n",
       " ((datetime.datetime(2021, 1, 1, 7, 0), 74), (86.57, 7)),\n",
       " ((datetime.datetime(2021, 1, 1, 7, 0), 42), (28.02, 3))]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_green \\\n",
    "    .filter(filter_outliers) \\\n",
    "    .map(prepare_for_grouping) \\\n",
    "    .reduceByKey(calculate_revenue)\\\n",
    "    .take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "RevenueRow = namedtuple('Revenue_green', ['hour', 'zone', 'revenue', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unwrap(row):\n",
    "    return RevenueRow(\n",
    "        hour=row[0][0], \n",
    "        zone=row[0][1],\n",
    "        revenue=row[1][0],\n",
    "        count=row[1][1]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "green_revenue_schema = types.StructType([\n",
    "    types.StructField('hour', types.TimestampType(), True),\n",
    "    types.StructField('zone', types.IntegerType(), True),\n",
    "    types.StructField('revenue', types.DoubleType(), True),\n",
    "    types.StructField('count', types.IntegerType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_green_revenue = rdd_green \\\n",
    "    .filter(filter_outliers) \\\n",
    "    .map(prepare_for_grouping) \\\n",
    "    .reduceByKey(calculate_revenue)\\\n",
    "    .map(unwrap)\\\n",
    "    .toDF(green_revenue_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+------------------+-----+\n",
      "|               hour|zone|           revenue|count|\n",
      "+-------------------+----+------------------+-----+\n",
      "|2021-01-01 07:00:00|  43|               6.8|    1|\n",
      "|2021-01-01 07:00:00| 166|             22.66|    2|\n",
      "|2021-01-01 07:00:00|  41|               8.3|    1|\n",
      "|2021-01-01 06:00:00| 168|               9.3|    1|\n",
      "|2021-01-01 07:00:00| 265|            216.36|    3|\n",
      "|2021-01-01 07:00:00|  75|             34.36|    3|\n",
      "|2021-01-01 07:00:00| 225|             85.41|    4|\n",
      "|2021-01-01 07:00:00| 244|              19.3|    1|\n",
      "|2021-01-01 07:00:00|  74|             86.57|    7|\n",
      "|2021-01-01 07:00:00|  42|             28.02|    3|\n",
      "|2021-01-01 07:00:00| 116|             55.59|    4|\n",
      "|2021-01-01 07:00:00|   7|             61.47|    2|\n",
      "|2021-01-01 07:00:00| 152|             84.92|    1|\n",
      "|2021-01-01 07:00:00|  82|              11.8|    1|\n",
      "|2021-01-01 07:00:00| 259|              29.0|    1|\n",
      "|2021-01-01 07:00:00| 247|             37.12|    2|\n",
      "|2021-01-01 07:00:00|  17|            102.34|    3|\n",
      "|2021-01-01 08:00:00| 173|             16.55|    1|\n",
      "|2021-01-01 08:00:00| 152|             14.55|    1|\n",
      "|2021-01-01 08:00:00|  41|52.129999999999995|    3|\n",
      "+-------------------+----+------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DF_green_revenue.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green_partition = spark.read.parquet('file\\green\\*')\n",
    "# df_green_partition = df_green.repartition(3) chia partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['VendorID', 'lpep_pickup_datetime', 'PULocationID', 'DOLocationID', 'trip_distance']\n",
    "\n",
    "rdd = df_green_partition \\\n",
    "    .select(columns) \\\n",
    "    .rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(df):\n",
    "    time = round(df.trip_distance * 5,3)\n",
    "    return time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trip_distance_km(df):\n",
    "    trip_km = round(df.trip_distance * 1.609344,3)\n",
    "    return trip_km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_prediction(rows):\n",
    "    df = pd.DataFrame(rows, columns=columns)\n",
    "    predictions = model_predict(df)\n",
    "    trip_km = trip_distance_km(df)\n",
    "    df['time_taxi_prediction'] = predictions\n",
    "    df['trip_km'] = trip_km\n",
    "    for row in df.itertuples():\n",
    "        yield row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predicts = rdd \\\n",
    "    .mapPartitions(time_prediction)\\\n",
    "    .toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+--------------------+------------+------------+-------------+--------------------+-------+\n",
      "|Index|VendorID|lpep_pickup_datetime|PULocationID|DOLocationID|trip_distance|time_taxi_prediction|trip_km|\n",
      "+-----+--------+--------------------+------------+------------+-------------+--------------------+-------+\n",
      "|    0|       2|                  {}|          43|         151|         1.01|                5.05|  1.625|\n",
      "|    1|       2|                  {}|         166|         239|         2.53|               12.65|  4.072|\n",
      "|    2|       2|                  {}|          41|          42|         1.12|                 5.6|  1.802|\n",
      "|    3|       2|                  {}|         168|          75|         1.99|                9.95|  3.203|\n",
      "|    4|       2|                  {}|         265|         265|          0.0|                 0.0|    0.0|\n",
      "|    5|       2|                  {}|         265|         265|          0.0|                 0.0|    0.0|\n",
      "|    6|       2|                  {}|         265|         265|          0.0|                 0.0|    0.0|\n",
      "|    7|       2|                  {}|          75|          75|         0.45|                2.25|  0.724|\n",
      "|    8|       2|                  {}|         225|         225|          0.0|                 0.0|    0.0|\n",
      "|    9|       2|                  {}|         225|         265|        12.19|               60.95| 19.618|\n",
      "|   10|       2|                  {}|         244|         244|         3.39|               16.95|  5.456|\n",
      "|   11|       2|                  {}|          75|         213|         6.69|               33.45| 10.767|\n",
      "|   12|       2|                  {}|          74|         238|         2.34|                11.7|  3.766|\n",
      "|   13|       2|                  {}|          74|          60|         5.48|                27.4|  8.819|\n",
      "|   14|       1|                  {}|          42|          41|          0.9|                 4.5|  1.448|\n",
      "|   15|       2|                  {}|          42|         264|          0.0|                 0.0|    0.0|\n",
      "|   16|       2|                  {}|          74|         116|         2.08|                10.4|  3.347|\n",
      "|   17|       2|                  {}|         116|         143|         4.64|                23.2|  7.467|\n",
      "|   18|       2|                  {}|          75|          42|         1.68|                 8.4|  2.704|\n",
      "|   19|       2|                  {}|          74|          75|         0.68|                 3.4|  1.094|\n",
      "+-----+--------+--------------------+------------+------------+-------------+--------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------+--------------------+\n",
      "|trip_km|time_taxi_prediction|\n",
      "+-------+--------------------+\n",
      "|  1.625|                5.05|\n",
      "|  4.072|               12.65|\n",
      "|  1.802|                 5.6|\n",
      "|  3.203|                9.95|\n",
      "|    0.0|                 0.0|\n",
      "|    0.0|                 0.0|\n",
      "|    0.0|                 0.0|\n",
      "|  0.724|                2.25|\n",
      "|    0.0|                 0.0|\n",
      "| 19.618|               60.95|\n",
      "|  5.456|               16.95|\n",
      "| 10.767|               33.45|\n",
      "|  3.766|                11.7|\n",
      "|  8.819|                27.4|\n",
      "|  1.448|                 4.5|\n",
      "|    0.0|                 0.0|\n",
      "|  3.347|                10.4|\n",
      "|  7.467|                23.2|\n",
      "|  2.704|                 8.4|\n",
      "|  1.094|                 3.4|\n",
      "+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_predicts.show()\n",
    "df_predicts.select('trip_km','time_taxi_prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
