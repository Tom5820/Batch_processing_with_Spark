{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('C:\\Spark\\spark-3.1.3-bin-hadoop3.2')\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import types\n",
    "import pandas as pd\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green = spark.read.parquet('file\\green_tripdata_2021-01.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[7] at javaToPython at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_green.rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_green = df_green \\\n",
    "    .select('lpep_pickup_datetime', 'PULocationID', 'total_amount') \\\n",
    "    .rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "start = datetime(year=2021, month=1, day=1)\n",
    "def filter_outliers(row):\n",
    "    return row.lpep_pickup_datetime >= start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(lpep_pickup_datetime=datetime.datetime(2021, 1, 1, 7, 15, 56), PULocationID=43, total_amount=6.8),\n",
       " Row(lpep_pickup_datetime=datetime.datetime(2021, 1, 1, 7, 25, 59), PULocationID=166, total_amount=16.86),\n",
       " Row(lpep_pickup_datetime=datetime.datetime(2021, 1, 1, 7, 45, 57), PULocationID=41, total_amount=8.3),\n",
       " Row(lpep_pickup_datetime=datetime.datetime(2021, 1, 1, 6, 57, 51), PULocationID=168, total_amount=9.3),\n",
       " Row(lpep_pickup_datetime=datetime.datetime(2021, 1, 1, 7, 16, 36), PULocationID=265, total_amount=-52.8)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_green.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(lpep_pickup_datetime=datetime.datetime(2021, 1, 1, 7, 15, 56), PULocationID=43, total_amount=6.8)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_green.filter(lambda row: row.lpep_pickup_datetime >= start ).take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_grouping(row): \n",
    "    hour = row.lpep_pickup_datetime.replace(minute=0, second=0, microsecond=0)\n",
    "    zone = row.PULocationID\n",
    "    key = (hour, zone)\n",
    "    \n",
    "    amount = row.total_amount\n",
    "    count = 1\n",
    "    value = (amount, count)\n",
    "\n",
    "    return (key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((datetime.datetime(2021, 1, 1, 7, 0), 43), (6.8, 1)),\n",
       " ((datetime.datetime(2021, 1, 1, 7, 0), 166), (16.86, 1)),\n",
       " ((datetime.datetime(2021, 1, 1, 7, 0), 41), (8.3, 1)),\n",
       " ((datetime.datetime(2021, 1, 1, 6, 0), 168), (9.3, 1)),\n",
       " ((datetime.datetime(2021, 1, 1, 7, 0), 265), (-52.8, 1)),\n",
       " ((datetime.datetime(2021, 1, 1, 7, 0), 265), (52.8, 1)),\n",
       " ((datetime.datetime(2021, 1, 1, 7, 0), 265), (216.36, 1)),\n",
       " ((datetime.datetime(2021, 1, 1, 7, 0), 75), (5.76, 1)),\n",
       " ((datetime.datetime(2021, 1, 1, 7, 0), 225), (3.8, 1)),\n",
       " ((datetime.datetime(2021, 1, 1, 7, 0), 225), (42.05, 1))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_green \\\n",
    "    .filter(filter_outliers) \\\n",
    "    .map(prepare_for_grouping) \\\n",
    "    .take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_revenue(left_value, right_value):\n",
    "    left_amount, left_count = left_value\n",
    "    right_amount, right_count = right_value\n",
    "    \n",
    "    output_amount = left_amount + right_amount\n",
    "    output_count = left_count + right_count\n",
    "    \n",
    "    return (output_amount, output_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((datetime.datetime(2021, 1, 1, 7, 0), 43), (6.8, 1)),\n",
       " ((datetime.datetime(2021, 1, 1, 7, 0), 166), (22.66, 2)),\n",
       " ((datetime.datetime(2021, 1, 1, 7, 0), 41), (8.3, 1)),\n",
       " ((datetime.datetime(2021, 1, 1, 6, 0), 168), (9.3, 1)),\n",
       " ((datetime.datetime(2021, 1, 1, 7, 0), 265), (216.36, 3)),\n",
       " ((datetime.datetime(2021, 1, 1, 7, 0), 75), (34.36, 3)),\n",
       " ((datetime.datetime(2021, 1, 1, 7, 0), 225), (85.41, 4)),\n",
       " ((datetime.datetime(2021, 1, 1, 7, 0), 244), (19.3, 1)),\n",
       " ((datetime.datetime(2021, 1, 1, 7, 0), 74), (86.57, 7)),\n",
       " ((datetime.datetime(2021, 1, 1, 7, 0), 42), (28.02, 3))]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_green \\\n",
    "    .filter(filter_outliers) \\\n",
    "    .map(prepare_for_grouping) \\\n",
    "    .reduceByKey(calculate_revenue)\\\n",
    "    .take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "RevenueRow = namedtuple('Revenue_green', ['hour', 'zone', 'revenue', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unwrap(row):\n",
    "    return RevenueRow(\n",
    "        hour=row[0][0], \n",
    "        zone=row[0][1],\n",
    "        revenue=row[1][0],\n",
    "        count=row[1][1]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "green_revenue_schema = types.StructType([\n",
    "    types.StructField('hour', types.TimestampType(), True),\n",
    "    types.StructField('zone', types.IntegerType(), True),\n",
    "    types.StructField('revenue', types.DoubleType(), True),\n",
    "    types.StructField('count', types.IntegerType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_green_revenue = rdd_green \\\n",
    "    .filter(filter_outliers) \\\n",
    "    .map(prepare_for_grouping) \\\n",
    "    .reduceByKey(calculate_revenue)\\\n",
    "    .map(unwrap)\\\n",
    "    .toDF(green_revenue_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+------------------+-----+\n",
      "|               hour|zone|           revenue|count|\n",
      "+-------------------+----+------------------+-----+\n",
      "|2021-01-01 07:00:00|  43|               6.8|    1|\n",
      "|2021-01-01 07:00:00| 166|             22.66|    2|\n",
      "|2021-01-01 07:00:00|  41|               8.3|    1|\n",
      "|2021-01-01 06:00:00| 168|               9.3|    1|\n",
      "|2021-01-01 07:00:00| 265|            216.36|    3|\n",
      "|2021-01-01 07:00:00|  75|             34.36|    3|\n",
      "|2021-01-01 07:00:00| 225|             85.41|    4|\n",
      "|2021-01-01 07:00:00| 244|              19.3|    1|\n",
      "|2021-01-01 07:00:00|  74|             86.57|    7|\n",
      "|2021-01-01 07:00:00|  42|             28.02|    3|\n",
      "|2021-01-01 07:00:00| 116|             55.59|    4|\n",
      "|2021-01-01 07:00:00|   7|             61.47|    2|\n",
      "|2021-01-01 07:00:00| 152|             84.92|    1|\n",
      "|2021-01-01 07:00:00|  82|              11.8|    1|\n",
      "|2021-01-01 07:00:00| 259|              29.0|    1|\n",
      "|2021-01-01 07:00:00| 247|             37.12|    2|\n",
      "|2021-01-01 07:00:00|  17|            102.34|    3|\n",
      "|2021-01-01 08:00:00| 173|             16.55|    1|\n",
      "|2021-01-01 08:00:00| 152|             14.55|    1|\n",
      "|2021-01-01 08:00:00|  41|52.129999999999995|    3|\n",
      "+-------------------+----+------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DF_green_revenue.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green_partition = spark.read.parquet('file\\green\\*')\n",
    "# df_green_partition = df_green.repartition(3) chia partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['VendorID', 'lpep_pickup_datetime', 'PULocationID', 'DOLocationID', 'trip_distance']\n",
    "\n",
    "rdd = df_green_partition \\\n",
    "    .select(columns) \\\n",
    "    .rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_to_model_in_batch(partition):\n",
    "    count = 0\n",
    "    for row in partition:\n",
    "        count = count +1\n",
    "    return [count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[76518, 64572]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.mapPartitions(apply_to_model_in_batch).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: long (nullable = true)\n",
      " |-- lpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- lpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- RatecodeID: double (nullable = true)\n",
      " |-- PULocationID: long (nullable = true)\n",
      " |-- DOLocationID: long (nullable = true)\n",
      " |-- passenger_count: double (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- ehail_fee: integer (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- payment_type: double (nullable = true)\n",
      " |-- trip_type: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_green_partition.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
